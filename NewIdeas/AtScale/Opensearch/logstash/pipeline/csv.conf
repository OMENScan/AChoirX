#############################
# INPUT
#############################
input {
  file {
    path => "/data/**/*.csv"
    mode => "read"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    file_completed_action => "delete"
    file_completed_log_path => "/usr/share/logstash/logs/completed.log"
  }
}

#############################
# FILTERS
#############################
filter {
  # Debug: keep original path for verification
  mutate { add_field => { "DEBUG_path" => "%{[log][file][path]}" } }

  # 1. Extract case-id, hostname, artifact filename
  grok {
    match => { "[log][file][path]" => ".*/data/(?<case_id>[^/]+)/(?<host_name>[^/]+)/(?<artifact_file>[^/]+\.csv)$" }
  }

  # 2. Defaults if parsing fails
  if ![case_id] or [case_id] == "" {
    mutate { replace => { "case_id" => "unknown" } }
  }

  if ![host_name] or [host_name] == "" {
    mutate { replace => { "host_name" => "unknown" } }
  }

  # 3. Normalize for OpenSearch index safety
  mutate { lowercase => ["case_id","host_name"] }

  # 4. Add fields for indexing
  mutate {
    add_field => {
      "[case][id]"        => "%{case_id}"
      "[host][name]"      => "%{host_name}"
      "[artifact][file]"  => "%{artifact_file}"
    }
  }

  # 5. Artifact-specific CSV parsing
  if [artifact_file] == "FLSOut.csv" {
    mutate { add_field => { "[artifact][type]" => "filelist" } }

    csv {
      separator => ","
      skip_header => true
      columns => ["fullpath","atime","mtime","ctime","size"]
      target => "filelist"
    }

    mutate { convert => { "[filelist][size]" => "integer" } }

  } else if [artifact_file] == "ts_Events_Logon.csv" {
    mutate { add_field => { "[artifact][type]" => "eventlog" } }

    csv {
      separator => ","
      skip_header => true
      columns => ["datetime","timestamp_desc","host","eventid","data","artifact","message"]
      target => "eventlog"
    }

  } else if [artifact_file] == "processes.csv" {
    mutate { add_field => { "[artifact][type]" => "processes" } }

    csv {
      separator => ","
      skip_header => true
      columns => ["process_name","pid","ppid","command_line"]
      target => "process"
    }

    mutate {
      convert => {
        "[process][pid]"  => "integer"
        "[process][ppid]" => "integer"
      }
    }

  } else if [artifact_file] == "network.csv" {
    mutate { add_field => { "[artifact][type]" => "network" } }

    csv {
      separator => ","
      skip_header => true
      columns => ["local_address","local_port","remote_address","remote_port","protocol","state"]
      target => "network"
    }

    mutate {
      convert => {
        "[network][local_port]"  => "integer"
        "[network][remote_port]" => "integer"
      }
    }

  } else {
    # Catch-all CSV parser for unknown artifacts
    mutate { add_field => { "[artifact][type]" => "unknown" } }
  }
}

#############################
# OUTPUT
#############################
output {
  if [case_id] != "unknown" and [host_name] != "unknown" {
    opensearch {
      hosts => ["http://opensearch-dfir:9200"]
      index => "dfir-%{case_id}-%{host_name}"
      user => "admin"
      password => "admin"
      ssl => false
    }
  } else {
    stdout { codec => rubydebug }  # For debugging unknowns
  }
}

